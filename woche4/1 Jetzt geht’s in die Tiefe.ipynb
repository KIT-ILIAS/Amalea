{"cells":[{"cell_type":"markdown","metadata":{"id":"s77bgj6dSweR"},"source":["# Jetzt geht‚Äôs in die Tiefese"]},{"cell_type":"markdown","metadata":{"id":"M7_95yszSweS"},"source":["## Regression mit neuronalen Netzen\n","\n","K√ºnstliche neuronale Netze werden verwendet, um eine Vielzahl von Problemen zu l√∂sen. Dabei werden wir uns zun√§chst auf die neuronalen Netze der Regression konzentrieren, da diese am Anfang leichter zu verstehen sind. Wir werden die Grundlagen von neuronalen Netzen kennenlernen, indem wir sie zur L√∂sung von beispielhaften Regressionsaufgaben verwenden werden. Zun√§chst wird das einzelne k√ºnstliche Neuron vorgestellt. Im n√§chsten Schritt werden wir Ihnen die Aktivierungsfunktionen mit interaktiven Aufgabenstellungen n√§her bringen, ehe wir uns der Backpropagation zuwenden.\n"]},{"cell_type":"markdown","metadata":{"id":"B0EwEUHiSweT"},"source":["### Das k√ºnstliche Neuron in der Theorie\n","\n","\n","Das k√ºnstliche Neuron ist eine mathematische Funktion, die sich an der Informationsverarbeitung einer biologischen Nervenzelle orientiert. Jedes Neuron nimmt einen oder mehrere Werte als Eingaben ($x_n$) entgegen und gibt einen Wert (y) aus. Dabei f√ºhrt es eine einfache mathematische Operation aus. (siehe (1) und Abb. 1):\n","\n","\n","\\begin{align}\n","f_{\\text{neuron}}(x) & = \\phi(\\sum_{n=1}^m {x_n \\cdot w_{n}} + b) \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; (1)\n","\\end{align}\n","\n","\n","- **Eingaben** $x_n$ sind numerische Werte, die durch die Daten oder durch andere Neuronen gegeben sind\n","- **Gewichte** $w_{n}$ werden mit den Eingangswerten multipliziert\n","- Es wird eine **Summe $v$** der gewichteten Eing√§nge berechnet\n","- Ein **konstanter Wert** $b$ wird zu der Summe addiert (sog. **Bias**)\n","- Eine **Aktivierungsfunktion $ùúô$** wird auf die Summe angewendet\n","- Der **Ausgang** $y$ kann als Eingabe f√ºr ein anderes Neuron oder als Endausgabe eines Netzes verwendet werden\n","\n","Die resultierende Ausgabe wird auch als die \"Aktivierung\" $y$ des Neurons bezeichnet.\n","Obwohl dieser Mechanismus sehr einfach ist, ist eine Vielzahl von einfachen Neuronen in der Lage, sehr komplexe Probleme zu l√∂sen.\n","\n","\n","<img src=\"images/neural_network.png\" />\n","<p style=\"text-align: center;\">\n","    Abb. 1 - Allgemeines k√ºnstliches Neuron\n","</p>"]},{"cell_type":"markdown","metadata":{"id":"DxY7ETukSweT"},"source":["<div class=\"alert alert-block alert-info\">\n","<b>Hinweis:</b>   \n","<ul>\n","<li>Ein k√ºnstliches Neuron ist nur ein abstraktes Konzept. Auch wenn wir in diesem Jupyter-Notebook <b>Neuron-Objekte</b> erstellen werden, um Code wiederverwenden zu k√∂nnen, ist ein Neuron nicht an eine bestimmte Form oder Implementierung gebunden. Es gibt sogar Ans√§tze, k√ºnstliche Neuronen mit <a href=\"https://www.osapublishing.org/optica/abstract.cfm?uri=optica-6-9-1132\">reiner Optik</a> zu realisieren.\n","Solange ein Objekt ein Verhalten zeigt, das durch die mathematische Funktion (1) beschrieben werden kann, k√∂nnen wir es als \"Neuron\" betrachten.\n","<li> Man k√∂nnte den Bias in die Summe in (1) integrieren, indem man ihn als $w_0$ mit einem entsprechenden $x_0 = 1$ bezeichnet.\n","</li>\n","</ul>\n","<br>\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"004SNA6uSweU"},"source":["### Ein einfaches Neuron in der Praxis\n","Zur Verdeutlichung betrachten wir nun ein Neuron mit nur einem einzigen Eingang und ohne Aktivierungsfunktion. Dieses Neuron ist bereits in der Lage, Funktionen der Form (2) zu modellieren. Das Neuron kann wie in Abbildung 2 visualisiert werden.\n","\n","\\begin{align}\n","f_{\\text{neuron}}(x) & = w * x + b \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;        (2)\n","\\end{align}\n","\n","\n","\n","<img src=\"images/single_neuron_no_activation.png\" />\n","<p style=\"text-align: center;\">\n","    Abb. 2 - Einfaches k√ºnstliches Neuron\n","</p>\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"deUGOB21SweU"},"source":["Unsere Neuronenklasse wird nur einen Eingang, ein Gewicht und einen Bias haben.\n","- Bei der Initialisierung wird sie mit einem interaktiven Plot verbunden.\n","- Ihre Gewichte und Bias k√∂nnen mit der Methode set_values ge√§ndert werden.\n","- Die Gewichte und Biaswerte k√∂nnen mit den Methoden get_weights/get_bias abgefragt werden.\n","- Wenn das Neuron modifiziert wird, benachrichtigt es den interaktiven Plot, damit dieser den Graphen aktualisiert.\n","- Sie verf√ºgt √ºber eine compute Methode, die die Aktivierung in Abh√§ngigkeit der Gewichte und des Eingangs berechnet."]},{"cell_type":"markdown","metadata":{"id":"-TqouP8kSweU"},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 4.1.1:</b> Implementieren Sie die in (2) beschriebene Funktion eines Neurons und speichern Sie das Ergebnis in der Variablen <code>value</code>.\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d4iZ6XwASweU"},"outputs":[],"source":["def y(x:list, w:float, b:float):\n","    #STUDENT CODE HERE\n","\n","    #STUDENT CODE until HERE\n","    return value"]},{"cell_type":"markdown","metadata":{"id":"EvGMrm4qSweV"},"source":["Schauen wir uns nun den Verlauf f√ºr <code>w=-1</code> und <code>b=1</code> an."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uoyfp93RSweW","executionInfo":{"status":"error","timestamp":1721801938271,"user_tz":-330,"elapsed":432,"user":{"displayName":"amalea","userId":"09783098087277097343"}},"outputId":"a3ed25a6-bb45-4d69-89d8-7cf13f604c5d","colab":{"base_uri":"https://localhost:8080/","height":210}},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'y' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-942d7fc4bec2>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"]}],"source":["w = -1\n","b = 1\n","values = []\n","for x in range(10):\n","    values.append(y(x, w, b))\n","\n","import matplotlib.pyplot as plt\n","\n","plt.figure()\n","plt.plot(range(10), values, marker='o', linestyle='dashed')\n","plt.xlabel('x')\n","plt.ylabel('y')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uHCeuOD5SweW"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python-amalea"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}