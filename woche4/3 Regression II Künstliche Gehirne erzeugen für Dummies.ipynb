{"cells":[{"cell_type":"markdown","metadata":{"id":"rr3d6nSQTEWh"},"source":["# Regression II: Künstliche Gehirne erzeugen für Dummies"]},{"cell_type":"markdown","metadata":{"id":"30qRvpdvTEWi"},"source":["## Neuronale Netze mit Deep Learning Bibliotheken\n","In diesem Notebook wollen wir herausfinden, wie wir neuronale Netze mithilfe von Deep Learning Bibliotheken trainieren können. Konkret werden wir dazu die drei Open Source Bibliotheken Keras, Tensorflow und Pytorch verwenden. Opensource ML-Bibliotheken und Frameworks erleichtern die Implementierung und das Training von (tiefen) neuronalen Netzen enorm. In diesem Notebook wollen wir Ihnen einen generellen Überblick über die Funktionsweise dieser drei Bibliotheken/Frameworks geben. Für die nächsten Notebooks von besonderer Relevanz ist die Keras Library, da wir diese noch häufiger verwenden werden. Wenn Sie sich für die Funktionsweise der beiden anderen Bibliotheken interessieren, können Sie sich zusätzlich die beiden darauf folgenden Code-Beispiele ansehen."]},{"cell_type":"markdown","metadata":{"id":"IRt0hrtATEWj"},"source":["### Datensatz für die Beispiele\n","Der Einfachheit halber werden wir für das Training aller drei Beispiel ML-Modelle den gleichen Datensatz verwenden, den wir im Folgenden in Form zweier Numpy Arrays definieren. Wie Sie vielleicht bereits bemerkt haben, handelt es sich dabei um das Ausgangsverhalten eines [XOR-Gates](https://de.wikipedia.org/wiki/Exklusiv-Oder-Gatter) (zu Deutsch: Exklusives-Oder-Gatter), das wir im Folgenden mit unseren Modellen erlenen möchten.\n","\n","![xor_gate_aufbau.svg](data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!-- Created with Inkscape (http://www.inkscape.org/) -->
<svg
   xmlns:dc="http://purl.org/dc/elements/1.1/"
   xmlns:cc="http://web.resource.org/cc/"
   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
   xmlns:svg="http://www.w3.org/2000/svg"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   width="201.96851"
   height="92.125984"
   id="svg2"
   sodipodi:version="0.32"
   inkscape:version="0.44.1"
   version="1.0"
   sodipodi:docbase="C:\Users\MovGP0\Desktop"
   sodipodi:docname="Mux-Aufbau_DIN40900.svg">
  <defs
     id="defs4" />
  <sodipodi:namedview
     id="base"
     pagecolor="#ffffff"
     bordercolor="#666666"
     borderopacity="1.0"
     inkscape:pageopacity="0.0"
     inkscape:pageshadow="2"
     inkscape:zoom="2.8"
     inkscape:cx="128.56802"
     inkscape:cy="83.031977"
     inkscape:document-units="mm"
     inkscape:current-layer="layer1"
     width="57mm"
     height="26mm"
     units="mm"
     showgrid="true"
     gridspacingx="1mm"
     gridspacingy="1mm"
     grid_units="mm"
     inkscape:grid-points="true"
     gridtolerance="0.4"
     inkscape:window-width="1024"
     inkscape:window-height="748"
     inkscape:window-x="1016"
     inkscape:window-y="-8"
     inkscape:object-bbox="true"
     inkscape:object-points="true"
     inkscape:object-nodes="true" />
  <metadata
     id="metadata7">
    <rdf:RDF>
      <cc:Work
         rdf:about="">
        <dc:format>image/svg+xml</dc:format>
        <dc:type
           rdf:resource="http://purl.org/dc/dcmitype/StillImage" />
      </cc:Work>
    </rdf:RDF>
  </metadata>
  <g
     inkscape:label="Ebene 1"
     inkscape:groupmode="layer"
     id="layer1">
    <path
       sodipodi:type="arc"
       style="fill:none;fill-opacity:1;stroke:black;stroke-width:1.47755909;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1"
       id="path3698"
       sodipodi:cx="39.375568"
       sodipodi:cy="183.10983"
       sodipodi:rx="0.39918929"
       sodipodi:ry="0"
       d="M 39.774758 183.10983 A 0.39918929 0 0 1 1  38.976379,183.10983 A 0.39918929 0 0 1 1  39.774758 183.10983 z" />
    <path
       style="fill:black;fill-opacity:1;fill-rule:evenodd;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1"
       d="M 159.44882,230.31496 L 17.716535,230.31496"
       id="path4820" />
    <rect
       style="fill:none;fill-opacity:1;stroke:black;stroke-width:0.99921262;stroke-miterlimit:4;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1"
       id="rect2248"
       width="24.80315"
       height="35.433071"
       x="81.261246"
       y="49.6063" />
    <path
       sodipodi:type="arc"
       style="fill:none;fill-opacity:1;stroke:black;stroke-width:1.0629921;stroke-miterlimit:4;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1"
       id="path3154"
       sodipodi:cx="63.77953"
       sodipodi:cy="49.595676"
       sodipodi:rx="3.5433066"
       sodipodi:ry="3.5539272"
       d="M 67.322836 49.595676 A 3.5433066 3.5539272 0 1 1  60.236223,49.595676 A 3.5433066 3.5539272 0 1 1  67.322836 49.595676 z"
       transform="translate(-39.05117,-35.42246)" />
    <text
       xml:space="preserve"
       style="font-size:12px;font-style:normal;font-weight:normal;fill:black;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;font-family:Bitstream Vera Sans"
       x="7.8103776"
       y="17.716509"
       id="text3156"><tspan
         sodipodi:role="line"
         id="tspan3158"
         x="7.8103776"
         y="17.716509">x</tspan></text>
    <path
       sodipodi:type="arc"
       style="fill:none;fill-opacity:1;stroke:black;stroke-width:1.0629921;stroke-miterlimit:4;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1"
       id="path3164"
       sodipodi:cx="63.77953"
       sodipodi:cy="49.595676"
       sodipodi:rx="3.5433066"
       sodipodi:ry="3.5539272"
       d="M 67.322836 49.595676 A 3.5433066 3.5539272 0 1 1  60.236223,49.595676 A 3.5433066 3.5539272 0 1 1  67.322836 49.595676 z"
       transform="translate(-38.97638,-14.16264)" />
    <text
       xml:space="preserve"
       style="font-size:12px;font-style:normal;font-weight:normal;fill:black;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;font-family:Bitstream Vera Sans"
       x="7.8851662"
       y="38.976368"
       id="text3166"><tspan
         sodipodi:role="line"
         id="tspan3168"
         x="7.8851662"
         y="38.976368">y</tspan></text>
    <path
       style="fill:none;fill-rule:evenodd;stroke:black;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1"
       d="M 151.91086,46.062979 L 180.25731,46.138909"
       id="path3176" />
    <path
       sodipodi:type="arc"
       style="fill:none;fill-opacity:1;stroke:black;stroke-width:1.0629921;stroke-miterlimit:4;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1"
       id="path3180"
       sodipodi:cx="63.77953"
       sodipodi:cy="49.595676"
       sodipodi:rx="3.5433066"
       sodipodi:ry="3.5539272"
       d="M 67.322836 49.595676 A 3.5433066 3.5539272 0 1 1  60.236223,49.595676 A 3.5433066 3.5539272 0 1 1  67.322836 49.595676 z"
       transform="translate(120.021,-3.456789)" />
    <text
       xml:space="preserve"
       style="font-size:12px;font-style:normal;font-weight:normal;fill:black;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;font-family:Bitstream Vera Sans"
       x="190.88724"
       y="49.184868"
       id="text3182"><tspan
         sodipodi:role="line"
         id="tspan3184"
         x="190.88724"
         y="49.184868">s</tspan></text>
    <text
       xml:space="preserve"
       style="font-size:12px;font-style:normal;font-weight:normal;fill:black;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;font-family:Bitstream Vera Sans"
       x="89.905739"
       y="71.546005"
       id="text3192"><tspan
         sodipodi:role="line"
         id="tspan3194"
         x="89.905739"
         y="71.546005">&amp;</tspan></text>
    <rect
       style="fill:none;fill-opacity:1;stroke:black;stroke-width:0.99921262;stroke-miterlimit:4;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1"
       id="rect3196"
       width="24.80315"
       height="35.433071"
       x="81.482689"
       y="7.0866008" />
    <text
       xml:space="preserve"
       style="font-size:12px;font-style:normal;font-weight:normal;fill:black;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;font-family:Bitstream Vera Sans"
       x="90.12719"
       y="29.026306"
       id="text3198"><tspan
         sodipodi:role="line"
         id="tspan3200"
         x="90.12719"
         y="29.026306">&amp;</tspan></text>
    <rect
       style="fill:none;fill-opacity:1;stroke:black;stroke-width:0.99921262;stroke-miterlimit:4;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1"
       id="rect3202"
       width="24.80315"
       height="35.433071"
       x="127.1077"
       y="28.346443" />
    <text
       xml:space="preserve"
       style="font-size:12px;font-style:normal;font-weight:normal;fill:black;fill-opacity:1;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;font-family:Bitstream Vera Sans"
       x="134.64568"
       y="50.286148"
       id="text3204"><tspan
         sodipodi:role="line"
         id="tspan3206"
         x="134.64568"
         y="50.286148">≥1</tspan></text>
    <path
       style="fill:none;fill-rule:evenodd;stroke:black;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1"
       d="M 127.1077,35.275578 L 116.47778,35.433058 L 116.47778,24.803136 L 105.84786,24.803136"
       id="path3208" />
    <path
       style="fill:none;fill-rule:evenodd;stroke:black;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1"
       d="M 127.1077,56.704149 L 116.47778,56.6929 L 116.47778,67.322822 L 105.84786,67.322822"
       id="path3210" />
    <path
       sodipodi:type="arc"
       style="fill:none;fill-opacity:1;stroke:black;stroke-width:1.0629921;stroke-miterlimit:4;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1"
       id="path3212"
       sodipodi:cx="63.77953"
       sodipodi:cy="49.595676"
       sodipodi:rx="3.5433066"
       sodipodi:ry="3.5539272"
       d="M 67.322836 49.595676 A 3.5433066 3.5539272 0 1 1  60.236223,49.595676 A 3.5433066 3.5539272 0 1 1  67.322836 49.595676 z"
       transform="translate(13.72188,-35.42246)" />
    <path
       sodipodi:type="arc"
       style="fill:none;fill-opacity:1;stroke:black;stroke-width:1.0629921;stroke-miterlimit:4;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1"
       id="path3214"
       sodipodi:cx="63.77953"
       sodipodi:cy="49.595676"
       sodipodi:rx="3.5433066"
       sodipodi:ry="3.5539272"
       d="M 67.322836 49.595676 A 3.5433066 3.5539272 0 1 1  60.236223,49.595676 A 3.5433066 3.5539272 0 1 1  67.322836 49.595676 z"
       transform="translate(13.8763,28.52506)" />
    <path
       style="fill:none;fill-rule:evenodd;stroke:black;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1"
       d="M 73.9581,14.173215 L 63.328178,14.173215 L 63.211488,56.614281 L 81.261246,56.611377"
       id="path3230" />
    <path
       style="fill:none;fill-rule:evenodd;stroke:black;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1"
       d="M 63.417133,14.173216 L 27.983225,14.173216"
       id="path3234"
       sodipodi:nodetypes="cc" />
    <path
       sodipodi:type="arc"
       style="fill:black;fill-opacity:1;stroke:black;stroke-width:0.99921262;stroke-miterlimit:4;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1"
       id="path3242"
       sodipodi:cx="53.149605"
       sodipodi:cy="-21.259855"
       sodipodi:rx="3.5433071"
       sodipodi:ry="3.5433071"
       d="M 56.692912 -21.259855 A 3.5433071 3.5433071 0 1 1  49.606298,-21.259855 A 3.5433071 3.5433071 0 1 1  56.692912 -21.259855 z"
       transform="matrix(0.712902,0,0,0.712902,25.48239,29.32941)" />
    <path
       sodipodi:type="arc"
       style="fill:black;fill-opacity:1;stroke:black;stroke-width:0.99921262;stroke-miterlimit:4;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1"
       id="path3248"
       sodipodi:cx="53.149605"
       sodipodi:cy="-21.259855"
       sodipodi:rx="3.5433071"
       sodipodi:ry="3.5433071"
       d="M 56.692912 -21.259855 A 3.5433071 3.5433071 0 1 1  49.606298,-21.259855 A 3.5433071 3.5433071 0 1 1  56.692912 -21.259855 z"
       transform="matrix(0.712902,0,0,0.712902,7.64845,50.58925)" />
    <path
       style="fill:none;fill-rule:evenodd;stroke:black;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1"
       d="M 45.611643,35.543435 L 81.482695,35.454149"
       id="path3250" />
    <path
       style="fill:none;fill-rule:evenodd;stroke:black;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1"
       d="M 28.346457,35.433062 L 46.062992,35.433062 L 46.062992,77.952747 L 74.112523,78.120736"
       id="path3252" />
  </g>
</svg>
)<img src=\"./images/xor_gate_aufbau.svg\"\n","     style=\"width:400px;\"\n","    />\n","<p style=\"text-align: center;\">\n","    Von 30px MovGP0 - selbst erstellt mit Inkscape, CC BY-SA 2.0 de, https://commons.wikimedia.org/w/index.php?curid=22912763\n","</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yXQId_-tTEWj"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VKOtnrlXTEWk"},"outputs":[],"source":["x_train = np.array([[0, 0],\n","                    [0, 1],\n","                    [1, 0],\n","                    [1, 1]], dtype = 'float64')\n","\n","y_train = np.array([[0],\n","                    [1],\n","                    [1],\n","                    [0]], dtype = 'float64')"]},{"cell_type":"markdown","metadata":{"id":"q46QlDa2TEWk"},"source":["### Keras Beispiel"]},{"cell_type":"markdown","metadata":{"id":"sKucBsl3TEWk"},"source":["#### Über Keras\n","\n","Keras ist eine Python Open-Source-Bibliothek für neuronale Netze. Sie fungiert als Schnittstelle für die TensorFlow-Bibliothek. Aufgrund ihres benutzerfreundlichen und modularen Aufbaus eignet sich Keras unter anderem besonders gut für das schnelle Experimentieren mit tiefen neuronalen Netzen. Mit nur wenigen Zeilen Code lassen sich die Schichten des neuronalen Netzes definieren, zu optimierende Verlustmetrik sowie Optimierungsverfahren festlegen und das Training starten.\n","\n","\n","#### Funktionsweise\n","Der einfachste Weg, ein neuronales Netz in Keras zu definieren ist über die Sequential API. Dabei wird im ersten Schritt ein Sequential Modell definiert, das als eine Art Basis funktioniert. Diesem Sequential Modell können wir dann Schritt für Schritt Ebenen mit `add()` hinzufügen. In unserem Beispiel erstellen wir ein neuronales Netz bestehend aus einem Denselayer (in Keras bezeichnet Denselayer einen \"fully connected Layer\") mit 3 Neuronen, gefolgt von einer ReLU Aktivierungsschicht und einem weiteren Ausgangs-Denselayer mit der Sigmoid Aktivierungsfunktion. Die Sigmoid Funktion im Ausgang liefert uns einen Wertebereich zwischen null und eins.\n","\n","Es sei angemerkt, dass das Modell wissen muss, welche Form der Eingabe (wie viele Dimensionen der Eingang hat) es erwarten soll. Aus diesem Grund muss die erste Schicht in einem Sequential Modell (und nur die erste, denn die folgenden Schichten können automatisch auf die Form schließen) Informationen über die Eingabeform erhalten. Dies erfolgt beispielsweise über das Festlegen des `input_dim` Arguments der ersten Schicht. Dies wird im Folgenden Beispiel umgesetzt.\n","\n","Ist das Keras-Modell fertig definiert, muss es vor dem Start des Trainings noch mit der `compile()`-Methode kompiliert werden. Dazu sollten wir die zu verwendene Verlustmetrik mit `loss` sowie den Optimizer mit `optimizer` festlegen. Keras unterstützt eine Vielzahl an Optimizern, die je nach Art verschiedene Einstellungsmöglichkeiten aufweisen.\n","Anschließend lässt sich das Training mit der `fit()`-Methode starten."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MlrsnSHBTEWk"},"outputs":[],"source":["# Load Library and modules\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Activation\n","from tensorflow.keras import optimizers\n","\n","# Init the model\n","model = Sequential()\n","model.add(Dense(3, input_dim=2))\n","model.add(Activation('relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Show optimizer\n","rmsprop = optimizers.RMSprop(learning_rate=0.01, rho=0.9)\n","\n","# Compile\n","model.compile(loss='binary_crossentropy',\n","              optimizer=rmsprop,\n","              metrics=['accuracy'])\n","# Train\n","model.fit(x_train, y_train, batch_size = 4,\n","          epochs=200)"]},{"cell_type":"markdown","metadata":{"id":"gP7vT1IcTEWk"},"source":["### (Optional) Tensorflow Beispiel"]},{"cell_type":"markdown","metadata":{"id":"qrUJPCU3TEWk"},"source":["#### Über Tensorflow\n","\n","TensorFlow ist eine Open-Source-Softwarebibliothek für die Datenflussprogrammierung und kann für eine Reihe von Aufgaben eingesetzt werden. Sie ist eine symbolische mathematische Bibliothek, die für maschinelle Lernanwendungen wie neuronale Netze verwendet wird.\n","\n","\n","\n","#### Funktionsweise\n","Das Definieren eines Modells in Tensorflow ist etwas umständlicher als in Keras, erlaubt es uns aber, genauere Einstellungen vorzunehmen. Im ersten Schritt definieren wir die Struktur unsere Daten mit sogenannte Placeholder mit der `tf.placeholder()` Funktion. Die Variable `phX` steht dabei für den Eingang und `phY` für den Ausgang. Beim Initialisieren dieser Placeholder können wir sowohl den Datentyp, in unserem Fall float32, als auch die Form der Daten (engl. shape) festlegen. In diesem Beispiel ist unser Eingang zweidimensional und unser Ausgang eindimensional, weshalb wir hier für `phX` 2 und `phY` 1 wählen. Das `None` an erster Stelle der Shape bedeutet dabei, dass die erste Dimension, die der Batch-Größe entspricht, eine beliebige Größe haben kann.\n","\n","Als nächstes initialisieren wir die Gewichte und Bias unseres Netzes mit zufälligen Startwerten. Beachten Sie, dass `w1` und `w2` bzw. `b1` und `b2` Matrizen sind, also mehrere Gewichte/Bias für einen Layer in einer Variablen vereinen.\n","\n","Diese initialisierten Gewichte und Bias können wir dann an die Feed-Forward Funktion `forward()` übergeben, in der wir den mathematische Zusammenhang zwischen Ein- und Ausgang in unserem Tensorflow-Netz definieren. In diesem Fall definieren wir ein Modell mit zwei Schichten. Der Ausgang beider Schichten ergibt sich jeweils durch Matrixmultiplikation (`tf.matmul()`) von Schichteingang und Gewichten der jeweiligen Schicht und anschließender Addition mit den Bias. In der ersten Schicht wird außerdem wieder die Sigmoid Funktion auf den Ausgang angewendet, während für die Ausgangsschicht die Softmax Funktion verwendet wird (hier direkt beim Berechnen der Kosten `cost`).\n","\n","Ähnlich wie beim Training mit Keras müssen wir auch bei Tensorflow Lernrate, die Anzahl an Epochen, die zu minimierende Kostenfunktion sowie das Optimierungsverfahren spezifizieren. Das Training kann anschließend durch das Erstellen einer neuen Session begonnen werden. In der anschließenden For-Loop führen wir die Session mit dem `run()` Befehl so häufig aus, wie durch die `nb_epochs` Variable spezifiziert, sodass wir das Training für die gewünschte Epochenanzahl durchführen.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n-FGyO0HTEWl"},"outputs":[],"source":["# Import tensorflow\n","import tensorflow as tf\n","\n","# Feedforward function\n","def forward(x, w1, b1, w2, b2):\n","\n","    Z = tf.nn.relu(tf.matmul(x,w1) + b1)\n","    Z2 = tf.matmul(Z,w2) + b2\n","\n","    return Z2\n","\n","def init_weights(shape):\n","    return tf.Variable(tf.random_normal(shape, stddev = 0.1))\n","\n","\n","# Define PlaceHolder for input x_train and output y_train\n","try:\n","    phX = tf.placeholder(tf.float32, [None, 2])\n","    phY = tf.placeholder(tf.float32, [None, 1])\n","except AttributeError:\n","    import tensorflow.compat.v1 as tf\n","    tf.disable_v2_behavior()\n","    phX = tf.placeholder(tf.float32, [None, 2])\n","    phY = tf.placeholder(tf.float32, [None, 1])\n","\n","# Init weights\n","w1 = init_weights([2, 3])\n","b1 = init_weights([3])\n","w2 = init_weights([3, 1])\n","b2 = init_weights([1])\n","\n","y_pred = forward(phX, w1, b1, w2, b2)\n","\n","lr = 0.1\n","nb_epochs = 201\n","\n","# Init cost function\n","cost = tf.reduce_mean(\n","    tf.nn.sigmoid_cross_entropy_with_logits(\n","        logits=y_pred, labels=phY))\n","\n","# Init optimizer\n","train = tf.train.AdamOptimizer(lr).minimize(cost)\n","\n","# Create session and init variables\n","init = tf.global_variables_initializer()\n","sess = tf.Session()\n","sess.run(init)\n","\n","# Start training\n","for i in range(nb_epochs):\n","    sess.run(train, feed_dict={phX: x_train, phY: y_train})\n","    c = sess.run(cost, feed_dict={phX: x_train, phY: y_train})\n","    if i%50 == 0:\n","        print(\"Iteration {: >8}  |  Cost: {}\".format(i,c))"]},{"cell_type":"markdown","metadata":{"id":"6X1hBrzYTEWl"},"source":["### (Optional) Pytorch Beispiel"]},{"cell_type":"markdown","metadata":{"id":"tpwlUHufTEWl"},"source":["#### Über Pytorch\n","PyTorch ist eine Open-Source-Bibliothek für maschinelles Lernen, die auf der Torch-Bibliothek basiert. Sie wird für Anwendungen wie Computer Vision und Verarbeitung natürlicher Sprache verwendet und hauptsächlich von Facebooks AI Research Lab entwickelt. Auch Pytorch ist ein kostenloses Opensource Projekt. Unterscheidungsmerkmal zu den vorherigen Bibliotheken ist die durchgängige Anwendung der Objektorientierung.\n","\n","#### Funktionsweise\n","Zunächst definieren wir eine neue Klasse `Net` die unser neuronales Netz repräsentiert. In der Init-Methode (Konstruktor) dieser Klasse initialisieren wir die beiden Schichten unseres Netzes. Anders als im vorherigen Tensorflow Beispiel müssen wir dabei die Shapes der beiden Schichten explizit angeben. In diesem Beispiel verwenden wir die [Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) Klasse, die eine lineare Transformation der Form  $y=xA^T+b$ durchführt. So können wir direkt unsere beiden Schichten `fc1` und `fc2` definieren. Wie auch bei der Tensorflow Implementation benötigen wir eine `forward` Methode, die uns den Ausgang des Netzes berechnet. Wir versehen den Ausgang der ersten Schicht `fc1` erneut mit der ReLU Funktion und geben diesen auf die zweite Schicht `fc2`. Auf den Ausgang dieser zweiten Schicht wenden wir dann die Sigmoid Aktivierungsfunktion an.\n","\n","Auch anders als bei der Implementation mit Tensorflow ist, dass wir beim Verwenden von Pytorch Torch Tensoren als Eingänge benötigen. Daher konvertieren wir unsere Numpy Trainingsdaten entsprechend.\n","\n","Auch hier können wir wichtige Einstellungen wie die Festlegung des Optimizers und der Verlustmetrik vornehmen, ehe wir mit dem Training beginnen.\n","\n","Während des Trainings innerhalb der For-Loop erfolgt jede Aktualisierung des Modells nach dem gleichen Muster:\n","\n","- Löschen des letzten Fehlergradienten: `optimizer.zero_grad()`\n","- Ein Vorwärtsdurchlauf (feedforward) der Eingabe durch das Modell: `net(input)`\n","- Berechnung des Verlusts für die Modellausgabe: `criterion(output, target)`\n","- Backpropagation des Fehlers durch das Modell: `loss.backward()`\n","- Aktualisieren des Modells, um den Verlust zu reduzieren: `optimizer.step()`\n","\n","Anders als bei der Tensorflow Implementation verschachteln wir dabei zwei For-Loops ineinander. Die innere Schleife füttert das Netz dabei jeweils mit einem einzelnen Eintrag aus unserem Datensatz (`input` und `target`), während die äußere Schleife die aktuelle Epoche steuert (`idx`).\n","\n"]},{"cell_type":"markdown","metadata":{"id":"wzlLZuPRTEWl"},"source":["<div class=\"alert alert-block alert-info\">\n","<b>Hinweis:</b> Um den unten stehenden Code auszuführen, installieren Sie bitte Pytorch, indem Sie das Suchwerkzeug (grafisch) in anaconda navigator verwenden. Bitte verändern Sie die Cuda Einstellungen nicht, wenn Sie Pytorch auf einem anderen Weg installieren!\n","\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XtLPIM6bTEWl"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","class Net(nn.Module):\n","\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.fc1 = nn.Linear(2, 3, True)\n","        self.fc2 = nn.Linear(3, 1, True)\n","\n","    def forward(self, x:float) -> float:\n","        x = F.relu(self.fc1(x))\n","        x = torch.sigmoid(self.fc2(x))\n","        return x\n","\n","net = Net()\n","\n","inputs = torch.from_numpy(x_train).type(torch.FloatTensor)\n","targets = torch.from_numpy(y_train).type(torch.FloatTensor)\n","\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(net.parameters(), lr=0.01)\n","\n","print(\"Training loop:\")\n","for idx in range(0, 201):\n","    for input, target in zip(inputs, targets):\n","        optimizer.zero_grad()   # zero the gradient buffers\n","        output = net(input)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()    # Does the update\n","    if idx % 50 == 0:\n","        print(\"Epoch: {: >8}  |  Loss: {}\".format(idx, loss.data.numpy()))"]},{"cell_type":"markdown","metadata":{"id":"7kcZx_d-TEWm"},"source":["### Praktische Aufgabe - Nonlinear Climate Control\n","\n","Im Aufgabenteil zur Regression mit neuronalen Netzen haben Sie bereits mit Daten eines Kühlsystems gearbeitet, die an dieser Stelle nochmals aufgegriffen werden.\n","Der Verlauf der Daten ist im folgenden nochmals dargestellt."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-3B93a8xTEWm"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","points_climate = dict(x=[25.0, 27.5, 30.0, 32.5, 35, 37.5, 40.0], y=[0.0, 2.0, 10.0, 23.7, 43, 68.7, 100.0])\n","plt.figure()\n","plt.scatter(points_climate['x'], points_climate['y'])\n","plt.xlabel('Temperatur in °C')\n","plt.ylabel('Optimale Arbeitslast in %')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sslCnutsTEWm"},"outputs":[],"source":["import numpy as np\n","mean_train_data = np.mean(points_climate['x'])\n","mean_train_labels = np.mean(points_climate['y'])\n","std_train_data = np.std(points_climate['x'])\n","std_train_labels = np.std(points_climate['y'])\n","train_data = [(x-mean_train_data) / std_train_data for x in points_climate['x']]\n","train_labels = [(x-mean_train_labels) / std_train_labels for x in points_climate['y']]"]},{"cell_type":"markdown","metadata":{"id":"cybg70RWTEWm"},"source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 4.3.1:</b> Implementieren Sie ein approximierendes Neuronales Netz mittels Keras. Das Netz soll die optimale Arbeitslast anhand der Temperatur vorhersagen. Speichern Sie das trainierte Modell in einer Variablen mit dem Namen <code>climate_model</code>.\n","    \n","Hinweise:\n","* Verwenden Sie die normierten Daten.\n","* Verwenden Sie <code>losses.MeanSquaredError</code> als Verlustfunktion.\n","* Passen Sie den Aufruf von <code>compile</code> an, sodass <code>metrics=[metrics.MeanSquaredError()]</code> übergeben wird.\n","* Verwenden Sie <code>RMSprop</code> mit einer Lernrate von 0.0001.\n","* Trainieren Sie 2000 Epochen mit einer Batch Size von 2.\n","* Das Neuronale Netz besitzt eine verdeckte Schicht mit 2 Neuronen.\n","\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gFZa1cX6TEWm"},"outputs":[],"source":["from tensorflow.keras import metrics\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Activation\n","from tensorflow.keras import optimizers, losses\n","\n","# STUDENT CODE HERE\n","\n","# STUDENT CODE until HERE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QfHeXpCiTEWm"},"outputs":[],"source":["from tensorflow.data import Dataset\n","from tensorflow.keras import metrics\n","x_values = [x for x in range(int(min(points_climate['x'])), int(max(points_climate['x']))+1)]\n","x_values_norm = [ (x - mean_train_data) / std_train_data for x in x_values]\n","test_data = Dataset.from_tensor_slices(x_values).batch(2)\n","y_pred = climate_model.predict(x_values_norm)\n","y_pred_denorm = [(x*std_train_labels)+mean_train_labels for x in y_pred]\n","\n","plt.figure()\n","plt.plot(points_climate['x'], points_climate['y'], marker='o', linestyle='None', label='Train data')\n","plt.plot(x_values, y_pred_denorm, label='Ausgabe Model', marker='o', linestyle='dashed')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jlrr0TJETEWm"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python-amalea"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}